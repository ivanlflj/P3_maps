{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenStreetMap Data Case Study\n",
    "## Área\n",
    "Rio de Janeiro, Brasil\n",
    "\n",
    "- [https://mapzen.com/data/metro-extracts/metro/rio-de-janeiro_brazil/](https://mapzen.com/data/metro-extracts/metro/rio-de-janeiro_brazil/)\n",
    "\n",
    "Preparação para rodar o caso em python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from xml.etree import cElementTree as ET\n",
    "import sqlite3 as lite\n",
    "import os\n",
    "import pandas as pd\n",
    "import P3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemas\n",
    "Vamos falar dos problemas.\n",
    "### Problema 1: A definição das ruas, avenidas, algumas vezes estão faltando e outras não estão padronizadas.\n",
    "Abaixo os exemplos de ruas com nomes errados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Servidão\n",
      "--- Servidão de Passagem 1\n",
      "--- Servidão de Passagem 1\n",
      "15\n",
      "--- 15 de Novembro\n",
      "Pça.\n",
      "--- Pça. da Bandeira\n",
      "Praca\n",
      "--- Praca Marechal Floriano\n",
      "Bernadino\n",
      "--- Bernadino dos Santos\n"
     ]
    }
   ],
   "source": [
    "expected_names = ['Rua', 'Avenida', 'Praia', 'Travessa', 'Praça', 'Estrada', 'Ladeira', 'Boulevard', 'Beco', 'Via', 'Largo',\n",
    "                 'Campo', 'Mirante', 'Acesso', 'Alameda', 'Rodovia', 'Parque', 'Auto', 'RJ-125']\n",
    "# Convertendo todos os dados para unicode, assim pode ser comparado\n",
    "expected_names = [name.decode('utf-8') for name in expected_names]\n",
    "            \n",
    "street_types_unexpected = P3.audit_1('rio-de-janeiro_brazil.osm', expected_names)\n",
    "\n",
    "P3.print_unexpected(street_types_unexpected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A maioria é necessário incluir na frente a palavra \"Rua\". As demais, \"R.\" e \"rua\" viram \"Rua, \"Av\" vira \"Avenida\", \"trav\" vira \"Travessa\", \"Estr.\" vira \"Estrada\", \"Pça.\" e \"Praca\" viram \"Praça\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2: Lugares estranhos e fora do padrão\n",
    "Segue abaixo todos os lugares na base de dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uma pequena amostra dos dados:\n",
      "Academia: 1\n",
      "Cassino: 1\n",
      "Clínica: 1\n",
      "Clínica Odontológica: 1\n",
      "Curso de Idiomas: 1\n",
      "Empada Brasil: 1\n"
     ]
    }
   ],
   "source": [
    "store_types = P3.audit_2('rio-de-janeiro_brazil.osm')\n",
    "\n",
    "print(\"Uma pequena amostra dos dados:\")\n",
    "counter = 0\n",
    "for key in sorted(store_types.iterkeys()):\n",
    "    counter += 1\n",
    "    print \"%s: %s\" % (key, store_types[key])\n",
    "    if counter == 6:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que 'Academia' pode virar 'gym'. Mas muitos são estranhos e podem ser removidos, como 'yes', 'f', 'other'. Sendo assim vamos remover todas as linhas com somente uma entrada, assim podemos retirar as linhas estranhas. No caso de não ser uma linha estranha ela é no mínimo irrelevante por só conter uma ocorrência."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 3: Formato do encoding\n",
    "Durante a programação houveram vários problemas de conversão unicode, encode, 'UTF-8' e ascii. Eles foram resolvidos no código, mas não foi algo simples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparação da base de dados\n",
    "Vamos preparar o SQL para fazer análise dos dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Criando o arquivo da base de dados\n",
    "if os.path.isfile('rio-de-janeiro_brazil.db'):\n",
    "    os.remove('rio-de-janeiro_brazil.db')\n",
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "\n",
    "# Criando as tabelas na base de dados\n",
    "P3.create_tables_sql(con)\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inserindo os dados na base de dados\n",
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "P3.create_data_sql(con,'rio-de-janeiro_brazil.osm')\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora a base de dados está feito, precisamos consertar os problemas apresentados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 1: A definição das ruas, avenidas, algumas vezes estão faltando e outras não estão padronizadas.\n",
    "Vamos resolver os nomes de ruas errados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "\n",
    "P3.fix_problem1(con)\n",
    "\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problema 2: A definição das ruas, avenidas, algumas vezes estão faltando e outras não estão padronizadas.\n",
    "Vamos remover os lugares estranhos e consertar a 'Academia'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "cur = con.cursor()\n",
    "# Transforma 'Academia' em 'gym'\n",
    "cur.execute('''UPDATE nodes_tags SET value = 'gym' WHERE value = 'Academia' and key = 'amenity' ''')\n",
    "# Remove casos com somente uma ocorrência\n",
    "cur.execute('''DELETE FROM nodes_tags WHERE key = 'amenity' and \n",
    "            value in (SELECT value FROM nodes_tags WHERE key = 'amenity' GROUP BY value HAVING count(*) = 1)''')\n",
    "con.commit()\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando csv\n",
    "Em um momento da análise é pedido a criação de CSVs, no caso vamos criá-los usando pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def create_csv_from_db(table_name):\n",
    "    '''Pega a tabela na base de dados e converte para csv'''\n",
    "    con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "    dataframe = pd.read_sql('''SELECT * FROM ''' + table_name, con)\n",
    "    con.close()\n",
    "    dataframe.to_csv(table_name + '.csv', encoding = 'utf-8')\n",
    "    \n",
    "create_csv_from_db('nodes')\n",
    "create_csv_from_db('ways')\n",
    "create_csv_from_db('nodes_tags')\n",
    "create_csv_from_db('ways_tags')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resultados\n",
    "Vamos agora apresentar estatísticas sobre os dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rio-de-janeiro_brazil.db: 88.95MB\n",
      "example.osm: 6.04MB\n",
      "rio-de-janeiro_brazil.osm: 329.25MB\n",
      "nodes.csv: 91.59MB\n",
      "nodes_tags.csv: 5.08MB\n",
      "ways.csv: 6.42MB\n",
      "ways_tags.csv: 15.03MB\n"
     ]
    }
   ],
   "source": [
    "def print_file_size(extension):\n",
    "    '''Verifica todos os arquivos na pasta com a extensão e imprime nome e tamanho em MB'''\n",
    "    for file_name in os.listdir('./'):\n",
    "        if file_name.endswith(extension):\n",
    "            print(file_name + \": \" + \"{:.2f}\".format(os.path.getsize(file_name)/1024./1024) + \"MB\")\n",
    "            \n",
    "print_file_size('.db')\n",
    "print_file_size('.osm')\n",
    "print_file_size('.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos notar que o arquivo '.db' é menor do que o '.csv' só da tabela nodes.\n",
    "\n",
    "Verificamos agora o número de usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os usuários com mais modificações foram:\n",
      "Id 893594 com 364055 modificações.\n",
      "Id 502691 com 162834 modificações.\n",
      "Id 4008694 com 155256 modificações.\n",
      "Id 139043 com 143376 modificações.\n",
      "Id 289524 com 84084 modificações.\n",
      "Id 481662 com 65527 modificações.\n",
      "Id 12293 com 54196 modificações.\n",
      "Id 82797 com 45644 modificações.\n",
      "Id 69210 com 32644 modificações.\n",
      "Id 2783588 com 32473 modificações.\n",
      "O total de usuários foi 1204.\n"
     ]
    }
   ],
   "source": [
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT uid, count(*) as num FROM nodes GROUP BY uid ORDER BY num desc LIMIT 10''')\n",
    "users_modify = cur.fetchall()\n",
    "print('Os usuários com mais modificações foram:')\n",
    "for user in users_modify:\n",
    "    print('Id {0} com {1} modificações.'.format(user[0], user[1]))\n",
    "cur.execute('''SELECT count(*) FROM (SELECT uid, count(*) as num FROM nodes GROUP BY uid)''')\n",
    "users = cur.fetchall()\n",
    "print('O total de usuários foi {}.'.format(users[0][0]))\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos analisar os nodes e ways."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O total de nodes foi 1576848.\n",
      "O total de ways foi 190756.\n"
     ]
    }
   ],
   "source": [
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT count(*) FROM (SELECT count(*) FROM nodes GROUP BY id)''')\n",
    "nodes = cur.fetchall()\n",
    "print('O total de nodes foi {}.'.format(nodes[0][0]))\n",
    "cur.execute('''SELECT count(*) FROM (SELECT count(*) FROM ways GROUP BY id)''')\n",
    "ways = cur.fetchall()\n",
    "print('O total de ways foi {}.'.format(ways[0][0]))\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uma amostra das lojas e quantidades são:\n",
      "A loja arts_centre tem 6 estabelecimentos no mapa.\n",
      "A loja atm tem 74 estabelecimentos no mapa.\n",
      "A loja bank tem 488 estabelecimentos no mapa.\n",
      "A loja bar tem 221 estabelecimentos no mapa.\n",
      "A loja bbq tem 3 estabelecimentos no mapa.\n",
      "A loja bench tem 74 estabelecimentos no mapa.\n",
      "A loja bicycle_parking tem 1469 estabelecimentos no mapa.\n",
      "A loja bicycle_rental tem 261 estabelecimentos no mapa.\n",
      "A loja brothel tem 14 estabelecimentos no mapa.\n",
      "A loja building tem 4 estabelecimentos no mapa.\n"
     ]
    }
   ],
   "source": [
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT value, count(*) FROM nodes_tags WHERE key = 'amenity' GROUP BY value''')\n",
    "stores = cur.fetchall()\n",
    "print('Uma amostra das lojas e quantidades são:')\n",
    "counter = 0\n",
    "for store in stores:\n",
    "    counter += 1\n",
    "    print('A loja {0} tem {1} estabelecimentos no mapa.'.format(store[0], store[1]))\n",
    "    if counter == 10:\n",
    "        break\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os 3 usuários que mais modificaram bares:\n",
      "O usuário 1746977 modificou 7 bares.\n",
      "O usuário 1281877 modificou 6 bares.\n",
      "O usuário 502691 modificou 5 bares.\n"
     ]
    }
   ],
   "source": [
    "# Colocar os 3 usuários que mais modificaram bares\n",
    "con = lite.connect('rio-de-janeiro_brazil.db')\n",
    "cur = con.cursor()\n",
    "cur.execute('''SELECT ways.uid, count(*) as num FROM ways, ways_tags WHERE ways.id = ways_tags.id and\n",
    "            ways_tags.key = 'amenity' and ways_tags.value = 'bar' GROUP BY ways.uid ORDER BY num desc LIMIT 3''')\n",
    "users = cur.fetchall()\n",
    "print('Os 3 usuários que mais modificaram bares:')\n",
    "for user in users:\n",
    "    print('O usuário {0} modificou {1} bares.'.format(user[0], user[1]))\n",
    "    \n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Futuras análises\n",
    "Pode ser avaliado futuramente informações como a média de nomes que cada usuário teve. Esse tipo de análise não teria muitas dificuldades, pode-se até analisar quais usuários mais tiveram diferentes nomes.\n",
    "\n",
    "Outra análise seria melhor tratar os tipos de estabelecimentos. O problema é que precisaria de uma análise mais apurada dos estabelecimentos. Por exemplo, para mim 'waste_basket' deve ser o mesmo que 'waste_disposal', mas precisa de uma análise para confirmar se essa informação está certa e como podemos juntá-la.\n",
    "\n",
    "Uma terceira análise possível seria verificar o CEP dos estabelecimentos usando \"Regular Expressions\". O problema seria como proceguir para os dados errados. O mesmo poderia ser corrigido com uma pesquisa na internet para cada endereço errado ou simplesmente apagado. O caso perfeito seria a correção dos mesmo, mas isso seria trabalhoso.\n",
    "\n",
    "## Referências\n",
    "- [http://stackoverflow.com/](http://stackoverflow.com/)\n",
    "- [https://www.openstreetmap.org](https://www.openstreetmap.org)\n",
    "- [https://mapzen.com/data/metro-extracts/](https://mapzen.com/data/metro-extracts/)\n",
    "- [https://wiki.openstreetmap.org](https://wiki.openstreetmap.org)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
